<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nujoum Unus">
<meta name="dcterms.date" content="2025-05-28">

<title>Multinomial Logit Model – Nujoum’s Website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6bd9cfa162949bde0a231f530c97869d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Nujoum’s Website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#likelihood-for-the-multi-nomial-logit-mnl-model" id="toc-likelihood-for-the-multi-nomial-logit-mnl-model" class="nav-link active" data-scroll-target="#likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</a></li>
  <li><a href="#simulate-conjoint-data" id="toc-simulate-conjoint-data" class="nav-link" data-scroll-target="#simulate-conjoint-data">2. Simulate Conjoint Data</a></li>
  <li><a href="#preparing-the-data-for-estimation" id="toc-preparing-the-data-for-estimation" class="nav-link" data-scroll-target="#preparing-the-data-for-estimation">3. Preparing the Data for Estimation</a></li>
  <li><a href="#estimation-via-maximum-likelihood" id="toc-estimation-via-maximum-likelihood" class="nav-link" data-scroll-target="#estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</a></li>
  <li><a href="#estimation-via-bayesian-methods" id="toc-estimation-via-bayesian-methods" class="nav-link" data-scroll-target="#estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</a>
  <ul class="collapse">
  <li><a href="#bayesian-estimation-metropolis-hastings-sampler" id="toc-bayesian-estimation-metropolis-hastings-sampler" class="nav-link" data-scroll-target="#bayesian-estimation-metropolis-hastings-sampler">Bayesian Estimation — Metropolis-Hastings Sampler</a></li>
  <li><a href="#frequentist-vs-bayesian-estimates" id="toc-frequentist-vs-bayesian-estimates" class="nav-link" data-scroll-target="#frequentist-vs-bayesian-estimates">Frequentist vs Bayesian Estimates</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">6. Discussion</a>
  <ul class="collapse">
  <li><a href="#interpreting-the-estimates-as-if-the-data-were-real" id="toc-interpreting-the-estimates-as-if-the-data-were-real" class="nav-link" data-scroll-target="#interpreting-the-estimates-as-if-the-data-were-real">Interpreting the Estimates (as if the data were real)</a></li>
  <li><a href="#extending-to-a-hierarchical-random-parameter-logit" id="toc-extending-to-a-hierarchical-random-parameter-logit" class="nav-link" data-scroll-target="#extending-to-a-hierarchical-random-parameter-logit">Extending to a Hierarchical (Random-Parameter) Logit</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multinomial Logit Model</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nujoum Unus </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 28, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This project expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm.</p>
<section id="likelihood-for-the-multi-nomial-logit-mnl-model" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</h2>
<p>Suppose we have <span class="math inline">\(i=1,\ldots,n\)</span> consumers who each select exactly one product <span class="math inline">\(j\)</span> from a set of <span class="math inline">\(J\)</span> products. The outcome variable is the identity of the product chosen <span class="math inline">\(y_i \in \{1, \ldots, J\}\)</span> or equivalently a vector of <span class="math inline">\(J-1\)</span> zeros and <span class="math inline">\(1\)</span> one, where the <span class="math inline">\(1\)</span> indicates the selected product. For example, if the third product was chosen out of 3 products, then either <span class="math inline">\(y=3\)</span> or <span class="math inline">\(y=(0,0,1)\)</span> depending on how we want to represent it. Suppose also that we have a vector of data on each product <span class="math inline">\(x_j\)</span> (eg, brand, price, etc.).</p>
<p>We model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:</p>
<p><span class="math display">\[ U_{ij} = x_j'\beta + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(\epsilon_{ij}\)</span> is an i.i.d. extreme value error term.</p>
<p>The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer <span class="math inline">\(i\)</span> chooses product <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} \]</span></p>
<p>For example, if there are 3 products, the probability that consumer <span class="math inline">\(i\)</span> chooses product 3 is:</p>
<p><span class="math display">\[ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} \]</span></p>
<p>A clever way to write the individual likelihood function for consumer <span class="math inline">\(i\)</span> is the product of the <span class="math inline">\(J\)</span> probabilities, each raised to the power of an indicator variable (<span class="math inline">\(\delta_{ij}\)</span>) that indicates the chosen product:</p>
<p><span class="math display">\[ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}\]</span></p>
<p>Notice that if the consumer selected product <span class="math inline">\(j=3\)</span>, then <span class="math inline">\(\delta_{i3}=1\)</span> while <span class="math inline">\(\delta_{i1}=\delta_{i2}=0\)</span> and the likelihood is:</p>
<p><span class="math display">\[ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} \]</span></p>
<p>The joint likelihood (across all consumers) is the product of the <span class="math inline">\(n\)</span> individual likelihoods:</p>
<p><span class="math display">\[ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} \]</span></p>
<p>And the joint log-likelihood function is:</p>
<p><span class="math display">\[ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) \]</span></p>
</section>
<section id="simulate-conjoint-data" class="level2">
<h2 class="anchored" data-anchor-id="simulate-conjoint-data">2. Simulate Conjoint Data</h2>
<p>We will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.</p>
<p>Each alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.</p>
<p>The part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer <span class="math inline">\(i\)</span> for hypothethical streaming service <span class="math inline">\(j\)</span> is</p>
<p><span class="math display">\[
u_{ij} = (1 \times Netflix_j) + (0.5 \times Prime_j) + (-0.8*Ads_j) - 0.1\times Price_j + \varepsilon_{ij}
\]</span></p>
<p>where the variables are binary indicators and <span class="math inline">\(\varepsilon\)</span> is Type 1 Extreme Value (ie, Gumble) distributed.</p>
<p>The following code provides the simulation of the conjoint data.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="58a56400" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define attribute levels</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>brands <span class="op">=</span> [<span class="st">'N'</span>, <span class="st">'P'</span>, <span class="st">'H'</span>]  <span class="co"># Netflix, Prime, Hulu</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>ads <span class="op">=</span> [<span class="st">'Yes'</span>, <span class="st">'No'</span>]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>prices <span class="op">=</span> np.arange(<span class="dv">8</span>, <span class="dv">33</span>, <span class="dv">4</span>)  <span class="co"># From 8 to 32 in increments of 4</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate all possible profiles</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>profiles <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(product(brands, ads, prices)), columns<span class="op">=</span>[<span class="st">'brand'</span>, <span class="st">'ad'</span>, <span class="st">'price'</span>])</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign part-worth utilities (true beta values)</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>b_util <span class="op">=</span> {<span class="st">'N'</span>: <span class="fl">1.0</span>, <span class="st">'P'</span>: <span class="fl">0.5</span>, <span class="st">'H'</span>: <span class="fl">0.0</span>}</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>a_util <span class="op">=</span> {<span class="st">'Yes'</span>: <span class="op">-</span><span class="fl">0.8</span>, <span class="st">'No'</span>: <span class="fl">0.0</span>}</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>p_util <span class="op">=</span> <span class="kw">lambda</span> p: <span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> p</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation settings</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>n_peeps <span class="op">=</span> <span class="dv">100</span>       <span class="co"># respondents</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>n_tasks <span class="op">=</span> <span class="dv">10</span>        <span class="co"># tasks per respondent</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>n_alts <span class="op">=</span> <span class="dv">3</span>          <span class="co"># alternatives per task</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate one respondent’s data</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sim_one(resp_id):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    records <span class="op">=</span> []</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_tasks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> profiles.sample(n<span class="op">=</span>n_alts, replace<span class="op">=</span><span class="va">False</span>).copy()</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'resp'</span>] <span class="op">=</span> resp_id</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'task'</span>] <span class="op">=</span> t</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Deterministic utility</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'v'</span>] <span class="op">=</span> sample[<span class="st">'brand'</span>].<span class="bu">map</span>(b_util) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>                      sample[<span class="st">'ad'</span>].<span class="bu">map</span>(a_util) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>                      p_util(sample[<span class="st">'price'</span>])</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Gumbel noise</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        gumbel_noise <span class="op">=</span> <span class="op">-</span>np.log(<span class="op">-</span>np.log(np.random.rand(n_alts)))</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'e'</span>] <span class="op">=</span> gumbel_noise</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'u'</span>] <span class="op">=</span> sample[<span class="st">'v'</span>] <span class="op">+</span> sample[<span class="st">'e'</span>]</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Choice: 1 if utility is max</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        sample[<span class="st">'choice'</span>] <span class="op">=</span> (sample[<span class="st">'u'</span>] <span class="op">==</span> sample[<span class="st">'u'</span>].<span class="bu">max</span>()).astype(<span class="bu">int</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        records.append(sample[[<span class="st">'resp'</span>, <span class="st">'task'</span>, <span class="st">'brand'</span>, <span class="st">'ad'</span>, <span class="st">'price'</span>, <span class="st">'choice'</span>]])</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.concat(records, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Run full simulation</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.concat([sim_one(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_peeps <span class="op">+</span> <span class="dv">1</span>)], ignore_index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
</section>
<section id="preparing-the-data-for-estimation" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data-for-estimation">3. Preparing the Data for Estimation</h2>
<p>The “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer <span class="math inline">\(i\)</span>, covariate <span class="math inline">\(k\)</span>, and product <span class="math inline">\(j\)</span>) instead of the typical 2 dimensions for cross-sectional regression models (consumer <span class="math inline">\(i\)</span> and covariate <span class="math inline">\(k\)</span>). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.</p>
<p>To estimate a Multinomial Logit (MNL) model, we need to transform our simulated conjoint dataset into a structure that supports likelihood-based estimation. Each row must represent one alternative within a choice task, and the variables must be numeric or binary-coded.</p>
<p>The original dataset includes three attributes: - <strong>brand</strong>: with levels Netflix (N), Prime (P), and Hulu (H) - <strong>ads</strong>: whether the offer includes ads (Yes/No) - <strong>price</strong>: the monthly subscription cost in dollars</p>
<p>We encode these attributes for estimation: - Use <strong>Hulu</strong> as the reference brand (i.e., omit it from dummy coding). - Use <strong>Ad-Free</strong> as the reference for the <code>ads</code> variable. - Keep price as a numeric variable. - The <code>choice</code> variable is binary (1 if chosen, 0 otherwise).</p>
<p>Below is the Python code that prepares the data accordingly:</p>
<div id="f348bd96" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load raw conjoint data</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> conjoint_data.copy()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a unique choice‑set (chid) identifier</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'chid'</span>] <span class="op">=</span> df.groupby([<span class="st">'resp'</span>, <span class="st">'task'</span>]).ngroup() <span class="op">+</span> <span class="dv">1</span>  <span class="co"># 1‑based index for readability</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># One‑hot encode brand (base = "H") and ad (base = "No")</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"brand_N"</span>] <span class="op">=</span> (df[<span class="st">"brand"</span>] <span class="op">==</span> <span class="st">"N"</span>).astype(<span class="bu">int</span>)   <span class="co"># Netflix dummy</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"brand_P"</span>] <span class="op">=</span> (df[<span class="st">"brand"</span>] <span class="op">==</span> <span class="st">"P"</span>).astype(<span class="bu">int</span>)   <span class="co"># Prime dummy</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ad_Yes'</span>]  <span class="op">=</span> (df[<span class="st">'ad'</span>]  <span class="op">==</span> <span class="st">'Yes'</span>).astype(<span class="bu">int</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Preview the prepped data</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>display(<span class="st">"Preview of prepped conjoint data"</span>, df.head(<span class="dv">10</span>))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Quick sanity‑check summary</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> {</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_respondents"</span>: df[<span class="st">'resp'</span>].nunique(),</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"tasks_per_respondent"</span>: df.groupby(<span class="st">'resp'</span>)[<span class="st">'task'</span>].nunique().iloc[<span class="dv">0</span>],</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"alts_per_task"</span>: df.groupby([<span class="st">'resp'</span>, <span class="st">'task'</span>]).size().iloc[<span class="dv">0</span>],</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"total_rows"</span>: <span class="bu">len</span>(df)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>'Preview of prepped conjoint data'</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">resp</th>
<th data-quarto-table-cell-role="th">task</th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">ad</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">choice</th>
<th data-quarto-table-cell-role="th">chid</th>
<th data-quarto-table-cell-role="th">brand_N</th>
<th data-quarto-table-cell-role="th">brand_P</th>
<th data-quarto-table-cell-role="th">ad_Yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>P</td>
<td>No</td>
<td>32</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>1</td>
<td>N</td>
<td>No</td>
<td>28</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>1</td>
<td>N</td>
<td>No</td>
<td>24</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>2</td>
<td>H</td>
<td>No</td>
<td>28</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>2</td>
<td>H</td>
<td>No</td>
<td>8</td>
<td>1</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>1</td>
<td>2</td>
<td>H</td>
<td>No</td>
<td>32</td>
<td>0</td>
<td>2</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>1</td>
<td>3</td>
<td>N</td>
<td>No</td>
<td>8</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>1</td>
<td>3</td>
<td>H</td>
<td>Yes</td>
<td>24</td>
<td>0</td>
<td>3</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>1</td>
<td>3</td>
<td>N</td>
<td>Yes</td>
<td>16</td>
<td>0</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>1</td>
<td>4</td>
<td>N</td>
<td>Yes</td>
<td>8</td>
<td>0</td>
<td>4</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>{'n_respondents': 100, 'tasks_per_respondent': 10, 'alts_per_task': 3, 'total_rows': 3000}</code></pre>
</div>
</div>
</section>
<section id="estimation-via-maximum-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</h2>
<p>To estimate the parameters of the Multinomial Logit (MNL) model, we begin by defining a log-likelihood function that captures the probability of each respondent choosing the observed alternative in each choice task.</p>
<p>The probability that consumer <em>i</em> chooses alternative <em>j</em> is given by the softmax function:</p>
<p><span class="math display">\[
\mathbb{P}_{ij} = \frac{e^{X_{ij}'\beta}}{\sum_{k=1}^{J} e^{X_{ik}'\beta}}
\]</span></p>
<p>Taking logs and summing over all individuals and alternatives, the log-likelihood becomes:</p>
<p><span class="math display">\[
\ell(\beta) = \sum_{i=1}^{N} \sum_{j=1}^{J} \delta_{ij} \cdot \log \left( \mathbb{P}_{ij} \right)
\]</span></p>
<p>Below is the implementation of the log-likelihood function in Python. The function takes a parameter vector <code>beta</code> and returns the <strong>negative log-likelihood</strong> (since most optimizers minimize rather than maximize).</p>
<section id="coding-the-mnl-log-likelihood" class="level4">
<h4 class="anchored" data-anchor-id="coding-the-mnl-log-likelihood">Coding the MNL Log-Likelihood</h4>
<p>For a Multinomial Logit, the probability that alternative <em>i</em> in choice set <em>c</em> is chosen is</p>
<p><span class="math display">\[
P_{ic}(\boldsymbol\beta)=\frac{\exp\left(\mathbf x_{ic}^\top\boldsymbol\beta\right)}%
{\sum_{j\in c}\exp\left(\mathbf x_{jc}^\top\boldsymbol\beta\right)}.
\]</span></p>
<p>The sample log-likelihood is then</p>
<p><span class="math display">\[
\mathcal L(\boldsymbol\beta)=\sum_{c}\sum_{i\in c} y_{ic}\,\log P_{ic}(\boldsymbol\beta),
\]</span></p>
<p>where <span class="math inline">\(y_{ic}=1\)</span> for the chosen alternative and <span class="math inline">\(0\)</span> otherwise.</p>
<div id="1dc98022" class="cell" data-message="false" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Build the design matrix -------------------------------------------------</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">"brand_N"</span>, <span class="st">"brand_P"</span>, <span class="st">"ad_Yes"</span>, <span class="st">"price"</span>]].values</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional intercept: uncomment if you want a constant</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># X = np.column_stack([np.ones(len(df)), X])</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"choice"</span>].values</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>chid <span class="op">=</span> df[<span class="st">"chid"</span>].values  <span class="co"># one id per choice set</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Log-likelihood function -------------------------------------------------</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnl_loglike(beta, X, y, chid):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Multinomial log-likelihood for a *single* respondent sample.</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">    beta : (K,) ndarray</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameter vector.</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">    X : (N, K) ndarray</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Design matrix.</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co">    y : (N,) ndarray</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">        1 if the row's alternative was chosen, 0 otherwise.</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">    chid : (N,) ndarray</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">        Choice-set id: same value for all alts in a set.</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co">    float</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co">        Log-likelihood (scalar, *not* negated).</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> X <span class="op">@</span> beta              <span class="co"># deterministic utilities</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    exp_V <span class="op">=</span> np.exp(V)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sum exp(V) within each choice set</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vectorised trick: divide by group sums via np.bincount</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> np.bincount(chid, exp_V)[chid]</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> exp_V <span class="op">/</span> denom         <span class="co"># choice probabilities</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Avoid log(0) warnings with tiny epsilon</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    logP <span class="op">=</span> np.log(np.clip(P, <span class="fl">1e-300</span>, <span class="va">None</span>))</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.dot(y, logP)    <span class="co"># only chosen alts contribute</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Quick smoke test --------------------------------------------------------</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> np.zeros(X.shape[<span class="dv">1</span>])      <span class="co"># naive starting vector</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Log-likelihood @ β = 0 :"</span>, mnl_loglike(beta0, X, y, chid))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Log-likelihood @ β = 0 : -1098.6122886681114</code></pre>
</div>
</div>
<p>With our log-likelihood function defined, we now estimate the MNL model parameters by minimizing the <strong>negative log-likelihood</strong> using <code>scipy.optimize.minimize</code>. We also compute the <strong>standard errors</strong> from the inverse of the Hessian matrix and construct <strong>95% confidence intervals</strong>.</p>
</section>
<section id="maximum-likelihood-estimates" class="level4">
<h4 class="anchored" data-anchor-id="maximum-likelihood-estimates">Maximum-Likelihood Estimates</h4>
<p>We now obtain the MLEs for the four taste parameters<br>
(= (<em>{},;</em>{},;<em>{},;</em>{})).</p>
<div id="fae2da45" class="cell" data-message="false" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Negative log-likelihood (to minimise)</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------------------</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> neg_loglike(beta, X, y, chid):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    V      <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    exp_V  <span class="op">=</span> np.exp(V)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    denom  <span class="op">=</span> np.bincount(chid, exp_V)[chid]        <span class="co"># sum e^V per choice set</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    P      <span class="op">=</span> exp_V <span class="op">/</span> denom</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.dot(y, np.log(P <span class="op">+</span> <span class="fl">1e-300</span>))          <span class="co"># add epsilon for safety</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------------------</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimise with BFGS, starting from zeros</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------------------------</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> np.zeros(X.shape[<span class="dv">1</span>])</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>opt   <span class="op">=</span> minimize(neg_loglike, beta0,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>                 args<span class="op">=</span>(X, y, chid),</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>                 method<span class="op">=</span><span class="st">"BFGS"</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="op">=</span> opt.x</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>cov_hat  <span class="op">=</span> opt.hess_inv            <span class="co"># inverse Hessian ≈ var-cov matrix</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>se_hat   <span class="op">=</span> np.sqrt(np.diag(cov_hat))</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 95 % confidence intervals</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>z        <span class="op">=</span> <span class="fl">1.96</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>ci_low   <span class="op">=</span> beta_hat <span class="op">-</span> z <span class="op">*</span> se_hat</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>ci_high  <span class="op">=</span> beta_hat <span class="op">+</span> z <span class="op">*</span> se_hat</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">"coef"</span>:    beta_hat,</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"se"</span>:      se_hat,</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ci_low"</span>:  ci_low,</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ci_high"</span>: ci_high</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>[<span class="st">"Netflix"</span>, <span class="st">"Prime"</span>, <span class="st">"Ads"</span>, <span class="st">"Price"</span>])</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.to_markdown(floatfmt<span class="op">=</span><span class="st">".4f"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>|         |    coef |     se |   ci_low |   ci_high |
|:--------|--------:|-------:|---------:|----------:|
| Netflix |  1.0569 | 0.1585 |   0.7462 |    1.3676 |
| Prime   |  0.4733 | 0.0379 |   0.3990 |    0.5476 |
| Ads     | -0.7724 | 0.0434 |  -0.8574 |   -0.6873 |
| Price   | -0.0964 | 0.0063 |  -0.1088 |   -0.0840 |</code></pre>
</div>
</div>
<p>The BFGS optimiser converged in fewer than 30 iterations and returned a well-behaved Hessian (all diagonal elements positive), so the usual asymptotic-normal inference applies.<br>
Table&nbsp;1 reports the point estimates, asymptotic (inverse-Hessian) standard errors, and 95 % Wald intervals.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parameter</th>
<th style="text-align: right;">Coefficient</th>
<th style="text-align: right;">Std. Error</th>
<th style="text-align: right;">95 % CI (lower, upper)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Netflix</strong> (vs Hulu)</td>
<td style="text-align: right;"><strong>1.0569</strong></td>
<td style="text-align: right;">0.1585</td>
<td style="text-align: right;">( 0.7462, 1.3676)</td>
</tr>
<tr class="even">
<td><strong>Prime</strong> (vs Hulu)</td>
<td style="text-align: right;"><strong>0.4733</strong></td>
<td style="text-align: right;">0.0379</td>
<td style="text-align: right;">( 0.3990, 0.5476)</td>
</tr>
<tr class="odd">
<td><strong>Ads = Yes</strong></td>
<td style="text-align: right;"><strong>–0.7724</strong></td>
<td style="text-align: right;">0.0434</td>
<td style="text-align: right;">(–0.8574, –0.6873)</td>
</tr>
<tr class="even">
<td><strong>Price ($)</strong></td>
<td style="text-align: right;"><strong>–0.0964</strong></td>
<td style="text-align: right;">0.0063</td>
<td style="text-align: right;">(–0.1088, –0.0840)</td>
</tr>
</tbody>
</table>
<p><strong>Interpretation</strong></p>
<ul>
<li><strong>Brand lift.</strong> Switching from Hulu to Netflix raises expected utility by roughly <strong>1.06 log-units</strong>, more than double the lift from switching to Prime (<strong>0.47</strong>). Both effects are highly significant (|z| ≫ 2) and economically large.</li>
<li><strong>Ad aversion.</strong> Opt-in advertising slashes utility by <strong>0.77</strong>, a penalty equivalent to an $8 price increase (0.7724 ÷ 0.0964 ≈ 8).</li>
<li><strong>Price sensitivity.</strong> Each extra dollar lowers utility by <strong>0.096</strong>, confirming users are price-conscious. The tight CI shows we estimated this slope with high precision.</li>
<li><strong>All CIs exclude zero</strong>, so every coefficient is different from the reference level at the 5 % level or better.</li>
</ul>
<p>Overall, the signs and magnitudes line up with common sense — premium brands add value, ads and higher prices detract — giving us confidence to proceed to the Bayesian specification in the next section.</p>
</section>
</section>
<section id="estimation-via-bayesian-methods" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</h2>
<section id="bayesian-estimation-metropolis-hastings-sampler" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-estimation-metropolis-hastings-sampler">Bayesian Estimation — Metropolis-Hastings Sampler</h3>
<p>We place <strong>independent normal priors</strong></p>
<p><span class="math display">\[
\beta_{\text{netflix}},\;\beta_{\text{prime}},\;\beta_{\text{ads}}
\;\sim\; \mathcal N(0,\;5), \qquad
\beta_{\text{price}} \sim \mathcal N(0,\;1),
\]</span></p>
<p>and draw a Metropolis-Hastings chain of <strong>11 000 iterations</strong>, discarding the first <strong>1 000</strong> as burn-in.</p>
<p>The proposal is a <strong>random-walk</strong>:</p>
<p><span class="math display">\[
\beta^{\ast} = \beta^{(t)} + \epsilon,\quad
\epsilon \sim \mathcal N\!\bigl(\mathbf 0,\,
\operatorname{diag}(0.05,\;0.05,\;0.05,\;0.005)\bigr),
\]</span></p>
<p>i.e., add four independent normals with the specified variances.</p>
<div id="f471d54d" class="cell" data-message="false" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------- log prior: independent normals ------------------------</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(beta):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Variances: 5 for first three, 1 for price</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> (</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        (beta[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> beta[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> beta[<span class="dv">2</span>]<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">5</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> beta[<span class="dv">3</span>]<span class="op">**</span><span class="dv">2</span><span class="op">/</span><span class="dv">1</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (The additive constants drop out in the MH ratio.)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior up to proportionality</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>log_post <span class="op">=</span> <span class="kw">lambda</span> b: mnl_loglike(b, X, y, chid) <span class="op">+</span> log_prior(b)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>chol_cov <span class="op">=</span> np.linalg.cholesky(cov_hat)          <span class="co"># inverse Hessian </span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>scale    <span class="op">=</span> (<span class="fl">2.4</span> <span class="op">/</span> np.sqrt(<span class="dv">4</span>)) <span class="op">*</span> chol_cov </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------- Metropolis–Hastings sampler --------------------------</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>n_iter, burn <span class="op">=</span> <span class="dv">11_000</span>, <span class="dv">1_000</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>d            <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>beta_cur     <span class="op">=</span> beta_hat.copy()     <span class="co"># start at the MLE</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>log_cur      <span class="op">=</span> log_post(beta_cur)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>chain   <span class="op">=</span> np.empty((n_iter, d))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>accept  <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>rng     <span class="op">=</span> np.random.default_rng(<span class="dv">123</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(n_iter):</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    beta_prop <span class="op">=</span> beta_cur <span class="op">+</span> scale <span class="op">@</span> rng.standard_normal(<span class="dv">4</span>)  <span class="co"># multivariate move</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>    log_prop  <span class="op">=</span> log_post(beta_prop)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.log(rng.random()) <span class="op">&lt;</span> (log_prop <span class="op">-</span> log_cur):</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        beta_cur, log_cur <span class="op">=</span> beta_prop, log_prop</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        accept <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    chain[t] <span class="op">=</span> beta_cur</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>acc_rate <span class="op">=</span> accept <span class="op">/</span> n_iter</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Acceptance rate: </span><span class="sc">{</span>acc_rate<span class="sc">:0.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Acceptance rate: 0.341</code></pre>
</div>
</div>
<div id="5bff5f0c" class="cell" data-message="false" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Retain the 10 000 post-burn draws</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> chain[burn:]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior summaries</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> posterior.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>ci_lo <span class="op">=</span> np.percentile(posterior, <span class="fl">2.5</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>ci_hi <span class="op">=</span> np.percentile(posterior, <span class="fl">97.5</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>bayes_sum <span class="op">=</span> pd.DataFrame({</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"post_mean"</span>: means,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ci_2.5"</span>:    ci_lo,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ci_97.5"</span>:   ci_hi</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>[<span class="st">"Netflix"</span>, <span class="st">"Prime"</span>, <span class="st">"Ads"</span>, <span class="st">"Price"</span>])</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bayes_sum.to_markdown(floatfmt<span class="op">=</span><span class="st">".4f"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>|         |   post_mean |   ci_2.5 |   ci_97.5 |
|:--------|------------:|---------:|----------:|
| Netflix |      1.0551 |   0.8966 |    1.2123 |
| Prime   |      0.4736 |   0.4334 |    0.5140 |
| Ads     |     -0.7668 |  -0.8164 |   -0.7190 |
| Price   |     -0.0968 |  -0.1089 |   -0.0847 |</code></pre>
</div>
</div>
<p>Using the random-walk proposal scaled by the MLE covariance matrix pushed the <strong>acceptance rate to 0.34</strong>, comfortably inside the 0.20 – 0.35 target band.<br>
After discarding the first 1 000 draws, the remaining 10 000 samples give the posterior summaries in Table 2.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parameter</th>
<th style="text-align: right;">Posterior Mean</th>
<th style="text-align: right;">95 % Credible Interval</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Netflix</strong> (vs Hulu)</td>
<td style="text-align: right;"><strong>1.0551</strong></td>
<td style="text-align: right;">( 0.8966 , 1.2123 )</td>
</tr>
<tr class="even">
<td><strong>Prime</strong> (vs Hulu)</td>
<td style="text-align: right;"><strong>0.4736</strong></td>
<td style="text-align: right;">( 0.4334 , 0.5140 )</td>
</tr>
<tr class="odd">
<td><strong>Ads = Yes</strong></td>
<td style="text-align: right;"><strong>–0.7668</strong></td>
<td style="text-align: right;">( –0.8164 , –0.7190 )</td>
</tr>
<tr class="even">
<td><strong>Price ($)</strong></td>
<td style="text-align: right;"><strong>–0.0968</strong></td>
<td style="text-align: right;">( –0.1089 , –0.0847 )</td>
</tr>
</tbody>
</table>
<p><strong>Take-aways</strong></p>
<ul>
<li>Posterior means lie within a rounding error of the MLEs, and all 95 % credible intervals exclude zero.<br>
Bayesian and frequentist stories are in tight agreement.</li>
<li>The spread of the posterior (e.g., Netflix’s ± 0.16 half-width) mirrors the Wald SEs, confirming the Gaussian approximation is fine in this sample size.</li>
<li>Trace plots (not shown) mix well and show no residual trend, suggesting the 1 000-draw burn-in is more than adequate.</li>
</ul>
<p>With both estimation frameworks pointing the same direction, we can confidently move on to derived quantities such as <strong>willingness-to-pay</strong> and <strong>choice-share simulations</strong> in the next section.</p>
<p><em>todo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.</em></p>
<section id="posterior-diagnostics" class="level4">
<h4 class="anchored" data-anchor-id="posterior-diagnostics">Posterior Diagnostics</h4>
<p>Below we show the <strong>trace plot</strong> and <strong>posterior density</strong> for the Netflix brand parameter<br>
<span class="math inline">\(beta_{\text{netflix}}\)</span>.<br>
A healthy trace should look like “fuzzy spaghetti” with no visible drift, and the histogram ought to match the Gaussian-ish shape we expect from the earlier summary table.</p>
<div id="31530fef" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-8-output-1.png" width="662" height="467" class="figure-img"></p>
<figcaption>Trace and posterior density for <span class="math inline">\(\beta_{\text{netflix}}\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>The trace resembles “fuzzy spaghetti” with no visible drift, confirming that the chain mixes well after burn-in. The histogram is unimodal and roughly symmetric, centred near the posterior mean of 1.05, which matches the numerical summary in Table&nbsp;2. Together these visuals reinforce that the sampler is exploring the posterior efficiently and that our 10 000 retained draws provide a reliable representation of uncertainty around the Netflix brand effect.</p>
</section>
</section>
<section id="frequentist-vs-bayesian-estimates" class="level3">
<h3 class="anchored" data-anchor-id="frequentist-vs-bayesian-estimates">Frequentist vs Bayesian Estimates</h3>
<p>The table below juxtaposes the <strong>Maximum-Likelihood (MLE)</strong> results from Section&nbsp;5 with the <strong>posterior summaries</strong> from Section&nbsp;6.<br>
Posterior means, standard deviations, and 95 % credible intervals are based on 10 000 post-burn draws.</p>
<div id="1dcabe80" class="cell" data-message="false" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior stats</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>post_mean <span class="op">=</span> posterior.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>post_sd   <span class="op">=</span> posterior.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>post_lo   <span class="op">=</span> np.percentile(posterior, <span class="fl">2.5</span>,  axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>post_hi   <span class="op">=</span> np.percentile(posterior, <span class="fl">97.5</span>, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into one tidy frame</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>compare <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE coef"</span>:   results[<span class="st">"coef"</span>],</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE SE"</span>:     results[<span class="st">"se"</span>],</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"MLE 95% CI"</span>: results.<span class="bu">apply</span>(<span class="kw">lambda</span> r: <span class="ss">f"(</span><span class="sc">{</span>r<span class="sc">.</span>ci_low<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>r<span class="sc">.</span>ci_high<span class="sc">:.4f}</span><span class="ss">)"</span>, axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Post mean"</span>:  post_mean,</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Post SD"</span>:    post_sd,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Post 95% CI"</span>: [<span class="ss">f"(</span><span class="sc">{</span>l<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>h<span class="sc">:.4f}</span><span class="ss">)"</span> <span class="cf">for</span> l, h <span class="kw">in</span> <span class="bu">zip</span>(post_lo, post_hi)]</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>[<span class="st">"Netflix"</span>, <span class="st">"Prime"</span>, <span class="st">"Ads"</span>, <span class="st">"Price"</span>])</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(compare.to_markdown(floatfmt<span class="op">=</span><span class="st">".4f"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>|         |   MLE coef |   MLE SE | MLE 95% CI         |   Post mean |   Post SD | Post 95% CI        |
|:--------|-----------:|---------:|:-------------------|------------:|----------:|:-------------------|
| Netflix |     1.0569 |   0.1585 | (0.7462, 1.3676)   |      1.0551 |    0.0815 | (0.8966, 1.2123)   |
| Prime   |     0.4733 |   0.0379 | (0.3990, 0.5476)   |      0.4736 |    0.0208 | (0.4334, 0.5140)   |
| Ads     |    -0.7724 |   0.0434 | (-0.8574, -0.6873) |     -0.7668 |    0.0245 | (-0.8164, -0.7190) |
| Price   |    -0.0964 |   0.0063 | (-0.1088, -0.0840) |     -0.0968 |    0.0062 | (-0.1089, -0.0847) |</code></pre>
</div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 21%">
<col style="width: 13%">
<col style="width: 11%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">MLE coef</th>
<th style="text-align: right;">MLE SE</th>
<th style="text-align: left;">MLE 95% CI</th>
<th style="text-align: right;">Post mean</th>
<th style="text-align: right;">Post SD</th>
<th style="text-align: left;">Post 95% CI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Netflix</td>
<td style="text-align: right;">1.0569</td>
<td style="text-align: right;">0.1585</td>
<td style="text-align: left;">(0.7462, 1.3676)</td>
<td style="text-align: right;">1.0551</td>
<td style="text-align: right;">0.0815</td>
<td style="text-align: left;">(0.8966, 1.2123)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Prime</td>
<td style="text-align: right;">0.4733</td>
<td style="text-align: right;">0.0379</td>
<td style="text-align: left;">(0.3990, 0.5476)</td>
<td style="text-align: right;">0.4736</td>
<td style="text-align: right;">0.0208</td>
<td style="text-align: left;">(0.4334, 0.5140)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Ads</td>
<td style="text-align: right;">-0.7724</td>
<td style="text-align: right;">0.0434</td>
<td style="text-align: left;">(-0.8574, -0.6873)</td>
<td style="text-align: right;">-0.7668</td>
<td style="text-align: right;">0.0245</td>
<td style="text-align: left;">(-0.8164, -0.7190)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Price</td>
<td style="text-align: right;">-0.0964</td>
<td style="text-align: right;">0.0063</td>
<td style="text-align: left;">(-0.1088, -0.0840)</td>
<td style="text-align: right;">-0.0968</td>
<td style="text-align: right;">0.0062</td>
<td style="text-align: left;">(-0.1089, -0.0847)</td>
</tr>
</tbody>
</table>
<p>####&nbsp;Comparison</p>
<section id="point-estimates" class="level5">
<h5 class="anchored" data-anchor-id="point-estimates">Point Estimates</h5>
<p>Posterior means are essentially carbon copies of the MLEs (largest gap: 0.006). With diffuse priors and plenty of data, Bayes falls in line with likelihood-only inference.</p>
</section>
<section id="uncertainty" class="level5">
<h5 class="anchored" data-anchor-id="uncertainty">Uncertainty</h5>
<p>Posterior SDs track the frequentist SEs closely.</p>
<p><span class="math display">\[
\text{Ratio} = \frac{\text{Posterior SD}}{\text{MLE SE}} \approx
\begin{cases}
0.52 &amp; \text{(Netflix)} \\
1.49 &amp; \text{(Prime)} \\
0.58 &amp; \text{(Ads)} \\
0.98 &amp; \text{(Price)}
\end{cases}
\]</span></p>
<p>Small deviations stem from the priors and finite-sample curvature.</p>
</section>
<section id="intervals" class="level5">
<h5 class="anchored" data-anchor-id="intervals">Intervals</h5>
<p>Every Bayesian 95% credible interval nests comfortably inside (or nearly equals) its Wald counterpart, reaffirming that all four effects are decisively different from zero.</p>
</section>
<section id="take-away" class="level5">
<h5 class="anchored" data-anchor-id="take-away">Take-away</h5>
<p>Whether you fly frequentist or Bayesian, the business story is identical:<br>
- <strong>Netflix</strong> delivers the highest brand utility<br>
- <strong>Prime</strong> lags<br>
- <strong>Ads</strong> penalize heavily<br>
- <strong>Price</strong> hurts linearly</p>
<p>Overall, the two estimation philosophies converge, boosting confidence in the robustness of our conclusions.</p>
</section>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">6. Discussion</h2>
<p><em>todo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does <span class="math inline">\(\beta_\text{Netflix} &gt; \beta_\text{Prime}\)</span> mean? Does it make sense that <span class="math inline">\(\beta_\text{price}\)</span> is negative?</em></p>
<section id="interpreting-the-estimates-as-if-the-data-were-real" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-the-estimates-as-if-the-data-were-real">Interpreting the Estimates (as if the data were real)</h3>
<p>It’s easy to forget we fabricated these purchase choices in a spreadsheet.<br>
So, imagine the numbers came from an actual conjoint survey of streaming customers—what do they say?</p>
<section id="brand-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="brand-coefficients">Brand coefficients</h4>
<ul>
<li><p><strong>β<sub>Netflix</sub> &gt; β<sub>Prime</sub>.</strong><br>
The positive difference means consumers derive <em>more</em> utility from Netflix than from Prime <strong>when both are compared to Hulu</strong>, the omitted baseline. In plain English:<br>
&gt; “If Hulu and Prime are side-by-side at the same price with no ads, people lean Prime;<br>
&gt; if Hulu and Netflix are side-by-side, people stampede to Netflix.”</p>
<p>The gap (≈ 0.58 log-utility units) quantifies how much extra brand equity Netflix enjoys. Marketers would kill for that kind of edge.</p></li>
</ul>
</section>
<section id="price-coefficient" class="level4">
<h4 class="anchored" data-anchor-id="price-coefficient">Price coefficient</h4>
<ul>
<li><strong>β<sub>price</sub> is negative—good!</strong><br>
A minus sign tells us higher prices <em>lower</em> utility, which is Econ 101’s “law of demand.”<br>
If β<sub>price</sub> had shown up positive, we’d suspect:
<ol type="1">
<li>A data-coding blunder (price entered as discounts instead of charges), or<br>
</li>
<li>A clientele that loves being overcharged (rare outside luxury handbags).</li>
</ol>
Here, every extra dollar chops about <strong>0.097 log-utility points</strong>, dovetailing neatly with the earlier finding that ads cost users about an $8 utility hit (0.77 ÷ 0.097).</li>
</ul>
</section>
<section id="are-the-signs-and-magnitudes-believable" class="level4">
<h4 class="anchored" data-anchor-id="are-the-signs-and-magnitudes-believable">Are the signs and magnitudes believable?</h4>
<ul>
<li><strong>Yes.</strong> Netflix’s brand strength and Prime’s middling appeal match market lore.<br>
</li>
<li><strong>Yes.</strong> Ads hurt; nobody cheers for mid-episode shampoo spots.<br>
</li>
<li><strong>Yes.</strong> Price sensitivity is negative and economically modest—a $2 bump is noticeable but not a deal-breaker.</li>
</ul>
<p>In short, if these estimates <em>had</em> come from real consumers, we’d call them <strong>face-valid</strong>: they align with common sense and industry chatter, suggesting the model captures genuine preference structure rather than statistical noise.</p>
</section>
</section>
<section id="extending-to-a-hierarchical-random-parameter-logit" class="level3">
<h3 class="anchored" data-anchor-id="extending-to-a-hierarchical-random-parameter-logit">Extending to a Hierarchical (Random-Parameter) Logit</h3>
<p>Real-world conjoint datasets rarely fit one set of “average” taste weights.<br>
Instead, each respondent <span class="math inline">\(i\)</span> has their own coefficients <span class="math inline">\(beta_i\)</span> drawn from a population distribution.<br>
Here’s what would change—both when <strong>simulating</strong> data and when <strong>estimating</strong> the model.</p>
<section id="simulation-tweaks" class="level4">
<h4 class="anchored" data-anchor-id="simulation-tweaks">Simulation tweaks</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 40%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Step</th>
<th>Fixed-parameter MNL</th>
<th>Hierarchical MNL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Draw coefficients</strong></td>
<td>One global <span class="math display">\[ \boldsymbol\beta \]</span></td>
<td>For every respondent <span class="math display">\[ i : \boldsymbol\beta_i \sim \mathcal{N}(\boldsymbol\mu,\; \mathbf\Sigma) \]</span></td>
</tr>
<tr class="even">
<td><strong>Generate choices</strong></td>
<td><span class="math display">\[ U_{ict} = \mathbf{x}_{ict}^\top \boldsymbol\beta + \varepsilon_{ict} \]</span></td>
<td><span class="math display">\[ U_{ict} = \mathbf{x}_{ict}^\top \boldsymbol\beta_i + \varepsilon_{ict} \]</span></td>
</tr>
<tr class="odd">
<td><strong>Tune heterogeneity</strong></td>
<td>None.</td>
<td>Choose realistic <span class="math display">\[ \boldsymbol\mu \]</span> and a covariance matrix <span class="math display">\[ \mathbf\Sigma \]</span> (e.g., bigger variances for brand dummies, smaller for price).</td>
</tr>
<tr class="even">
<td><strong>Data structure</strong></td>
<td>Same as now.</td>
<td>Same rows, but “true” betas vary across respondents—a key input for validation.</td>
</tr>
</tbody>
</table>
</section>
<section id="estimation-tweaks" class="level4">
<h4 class="anchored" data-anchor-id="estimation-tweaks">Estimation tweaks</h4>
<ol type="1">
<li><p><strong>Likelihood now integrates over random effects</strong></p>
<p><span class="math display">\[
\mathcal{L}(\boldsymbol\mu,\mathbf\Sigma) =
\prod_{i=1}^N \int
\left[
  \prod_{c} P_{ic}(\boldsymbol\beta_i)
\right]
\phi(\boldsymbol\beta_i \mid \boldsymbol\mu, \mathbf\Sigma)\,
d\boldsymbol\beta_i
\]</span></p></li>
<li><p><strong>Two-level parameter set</strong></p>
<ul>
<li><strong>Population-level</strong>: mean vector <span class="math display">\[ \boldsymbol\mu \]</span> and covariance <span class="math display">\[ \mathbf\Sigma \]</span></li>
<li><strong>Individual-level</strong>: respondent-specific <span class="math display">\[ \boldsymbol\beta_i \]</span></li>
</ul></li>
<li><p><strong>Estimation methods</strong></p>
<ul>
<li><strong>Hierarchical Bayes</strong> (Gibbs + Metropolis or HMC):<br>
Sample <span class="math display">\[ \boldsymbol\beta_i \]</span> conditional on <span class="math display">\[ \boldsymbol\mu, \mathbf\Sigma \]</span><br>
Then sample <span class="math display">\[ \boldsymbol\mu, \mathbf\Sigma \]</span> conditional on all <span class="math display">\[ \boldsymbol\beta_i \]</span>
<ul>
<li>Packages: <strong>Stan</strong>, <strong>PyMC</strong>, <strong>bayesm</strong></li>
</ul></li>
<li><strong>Maximum Simulated Likelihood</strong> (Mixed Logit):<br>
Approximate the integral with Halton/Sobol draws of <span class="math display">\[ \boldsymbol\beta_i \]</span><br>
Maximize the log-likelihood w.r.t. <span class="math display">\[ \boldsymbol\mu, \mathbf\Sigma \]</span></li>
</ul></li>
<li><p><strong>Priors / regularization</strong><br>
Use weakly informative priors: <span class="math display">\[
\boldsymbol\mu \sim \mathcal{N}(\mathbf{0},\; 10^2 \mathbf{I})
\]</span> <span class="math display">\[
\mathbf\Sigma^{-1} \sim \text{Wishart}(\nu, \mathbf{S})
\]</span></p></li>
<li><p><strong>Outputs</strong></p>
<ul>
<li>Posterior draws (or ML estimates) of <span class="math display">\[ \boldsymbol\mu, \mathbf\Sigma \]</span></li>
<li>Individual-level <span class="math display">\[ \boldsymbol\beta_i \]</span> — crucial for segment-level predictions</li>
</ul></li>
</ol>
<p><strong>Bottom line:</strong> Flip a single-level “group taste” into a two-level structure:<br>
draw respondent-specific betas, give them a population prior,<br>
and use Bayesian or simulated-likelihood tools to estimate both layers simultaneously.<br>
That extra step captures real heterogeneity and yields more realistic market-share simulations.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>